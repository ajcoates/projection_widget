{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 12 fields in line 1989, saw 13\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f2d797583bab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mworkday\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'usersChanges_2021_02_15_11_54.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrevenue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'duplicates.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprojects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'iheart_projects.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2057\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2059\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2060\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 12 fields in line 1989, saw 13\n"
     ]
    }
   ],
   "source": [
    "empl_roll = pd.DataFrame(pd.read_csv('CR Indexed Worker Roster - Sales 2021-01-04 19_16 CST.xlsx - Sheet1.csv'))\n",
    "user_df = pd.DataFrame(pd.read_csv('ihm_users.csv'))\n",
    "market_owners = pd.DataFrame(pd.read_csv('ihm_account_management.csv'))\n",
    "workday = pd.DataFrame(pd.read_csv('usersChanges_2021_02_15_11_54.csv'))\n",
    "revenue = pd.DataFrame(pd.read_csv('duplicates.csv'))\n",
    "projects = pd.DataFrame(pd.read_csv('iheart_projects.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empl_roll[empl_roll.apply(lambda row: row.astype(str).str.contains('Albany', case=False).any(), axis=1)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revenue[revenue.apply(lambda row: row.astype(str).str.contains('Hatties', case=False).any(), axis=1)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task:\n",
    "\n",
    "### Read-in Employee Roll\n",
    "### Read-in Usership Database Pull\n",
    "### Read-in Monday.com market ownership report\n",
    "### Create lists of markets by owner\n",
    "### Append owners name in new \"Owner\" column in user_df\n",
    "### Sort by first project date OR date of hire (tentative pending LW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creates a list for each team member of the markets he/she owns\n",
    "# Casts group names to lowercase to aid in matching\n",
    "user_df.group = user_df['group'].str.lower()\n",
    "# Casts market names to lowercase to aid in matching\n",
    "market_owners.Name = market_owners.Name.str.lower()\n",
    "\n",
    "arliss = market_owners[market_owners['Owner'] == 'Arliss Coates']\n",
    "arliss = arliss.Name.tolist()\n",
    "\n",
    "ashley = market_owners[market_owners['Owner'] == 'Ashley McCarthy']\n",
    "ashley = ashley['Name'].tolist()\n",
    "\n",
    "jenny = market_owners[market_owners['Owner'] == 'Jenny Donheiser']\n",
    "jenny = jenny['Name'].tolist()\n",
    "\n",
    "mariana = market_owners[market_owners['Owner'] == 'Mariana E Trevino Stafford']\n",
    "mariana = mariana['Name'].tolist()\n",
    "\n",
    "# Strips whitespace from group names in user_df\n",
    "user_df.group = user_df.group.str.strip()\n",
    "\n",
    "# # renaming special cases due to human error\n",
    "user_df.loc[(user_df.group == 'mccallen, tx'),'group'] = 'mcallen, tx'\n",
    "user_df.loc[(user_df.group == 'modesto / stockton, ca'), 'group'] = 'modesto/stockton, ca'\n",
    "user_df.loc[(user_df.group == 'st. petersburg, fl | inside sales'), 'group'] = 'inside sales'\n",
    "user_df.loc[(user_df.group == 'tuscaloose, al'), 'group'] = 'tuscaloosa, al'\n",
    "# Lexington and Somerset are distinct markets in iHeart's system\n",
    "user_df.loc[(user_df.group == 'lexington / somerset, ky'), 'group'] = 'lexington, ky'\n",
    "user_df.loc[(user_df.group == 'roanoke / lynchburg, va'), 'group'] = 'roanoke/lynchburg, va'\n",
    "\n",
    "# # Slicing user_df by market owner\n",
    "\n",
    "arliss_users = user_df.loc[user_df['group'].isin(arliss)]\n",
    "\n",
    "ashley_users = user_df.loc[user_df['group'].isin(ashley)]\n",
    "\n",
    "jenny_users = user_df.loc[user_df['group'].isin(jenny)]\n",
    "\n",
    "mariana_users = user_df.loc[user_df['group'].isin(mariana)]\n",
    "\n",
    "print('arliss_users: ' + str(arliss_users.shape), '\\n'\n",
    "'ashley_users: ' + str(ashley_users.shape), '\\n'\n",
    "'jenny_users: ' + str(jenny_users.shape), '\\n'\n",
    "'mariana_users: ' + str(mariana_users.shape))\n",
    "\n",
    "print('arliss projects/users: ' + str(arliss_users.projects.sum()/arliss_users.shape[0]), '\\n'\n",
    "      'arliss projects: ' + str(arliss_users.projects.sum()), '\\n'\n",
    "      'ashley projects/users: ' + str(ashley_users.projects.sum()/arliss_users.shape[0]), '\\n'\n",
    "      'ashley projects: ' + str(ashley_users.projects.sum()), '\\n'\n",
    "      'jenny projects/users: ' + str(jenny_users.projects.sum()/arliss_users.shape[0]), '\\n'\n",
    "      'jenny projects: ' + str(jenny_users.projects.sum()), '\\n'\n",
    "      'mariana projects/users: ' + str(mariana_users.projects.sum()/arliss_users.shape[0]), '\\n'\n",
    "      'mariana projects: ' + str(mariana_users.projects.sum()))\n",
    "\n",
    "\n",
    "# # Sense checking; making sure the number of markets in each team member's subset of df_users\n",
    "# # matches the full list of that team member's markets\n",
    "\n",
    "print('arliss groups in user_df: ' + str(len(arliss_users.group.unique())), '\\n'\n",
    "      'arliss groups in market_owners :' + str(len(arliss)))\n",
    "\n",
    "print('ashley groups in user_df: ' + str(len(ashley_users.group.unique())), '\\n'\n",
    "      'ashley groups in market_owners: ' + str(len(ashley)))\n",
    "\n",
    "print('jenny groups in user_df: ' + str(len(jenny_users.group.unique())), '\\n'\n",
    "      'jenny groups in market_owners: ', len(jenny))\n",
    "\n",
    "print('mariana groups in user_df: ', len(mariana_users.group.unique()), '\\n'\n",
    "      'mariana groups in market_owners: ', len(mariana))\n",
    "\n",
    "print('users_df shape: ' + str(user_df.shape))\n",
    "print('empl_roll shape: ' + str(empl_roll.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'arliss_users' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-bab0ff83f0ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# # Adding new field \"owner\" to each team member's subset of user_df for the purpose of concatenating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# # these dataframes in the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0marliss_users\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'owner'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Arliss'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mashley_users\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'owner'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Ashley'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mjenny_users\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'owner'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Jenny'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'arliss_users' is not defined"
     ]
    }
   ],
   "source": [
    "# # Adding new field \"owner\" to each team member's subset of user_df for the purpose of concatenating\n",
    "# # these dataframes in the following code\n",
    "arliss_users['owner'] = 'Arliss'\n",
    "ashley_users['owner'] = 'Ashley'\n",
    "jenny_users['owner'] = 'Jenny'\n",
    "mariana_users['owner'] = 'Mariana'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defines variable \"frames\" as a list of the user_df subsets so as\n",
    "#### to concatenate them in the following line. Redefining variable \"user_df\"\n",
    "#### as the same dataframe but with \"owner\" column added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_df shape is:  (3112, 9) \n",
      "empl_roll shape is:  (2183, 17) \n",
      "registered users minus employees on file:  929 \n",
      "merged shape is:  (3499, 25)\n"
     ]
    }
   ],
   "source": [
    "frames = [arliss_users, ashley_users, jenny_users, mariana_users]\n",
    "user_df = pd.concat(frames)\n",
    "\n",
    "user_df.to_csv('ihm_users_with_owner.csv', index = 0)\n",
    "\n",
    "empl_roll['Email - Primary Work'] = empl_roll['Email - Primary Work'].str.lower()\n",
    "empl_roll.rename(columns = {'Email - Primary Work': 'email'}, inplace=True)\n",
    "\n",
    "user_df.email = user_df.email.str.lower()\n",
    "filtered_users = user_df.groupby('email').filter(lambda x : len(x)==1)\n",
    "\n",
    "empl_roll.Market = empl_roll.Market.str.lower()\n",
    "empl_roll.Market = [x.replace(' - market', '') for x in empl_roll.Market]\n",
    "\n",
    "merged = pd.DataFrame(pd.merge(user_df, empl_roll, on='email', how='outer'))\n",
    "\n",
    "merged.to_csv('merged_hr_and_users.csv')\n",
    "\n",
    "\n",
    "\n",
    "print('user_df shape is: ', user_df.shape, '\\n'\n",
    "     'empl_roll shape is: ', empl_roll.shape ,'\\n'\n",
    "     'registered users minus employees on file: ', user_df.shape[0] - empl_roll.shape[0], '\\n'\n",
    "     'merged shape is: ', merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.loc[merged['name'].str.split().str.len() == 2, 'first name'] = merged['name'].str.split().str[0]\n",
    "\n",
    "virginia = merged.loc[(merged.projects <= 5) &\n",
    "                     (merged['Region/Area'].str.contains('Virginia')) &\n",
    "                     merged['Job Title'].str.contains('Acc')].groupby('email').filter(lambda x : len(x)== 1)[['email', 'first name', 'Market', 'projects']]\n",
    "# virginia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empl_roll[empl_roll['Job Title'].str.contains('Account', na=False)]['Job Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empl_roll, user_df, workday\n",
    "allmerge = pd.DataFrame(pd.merge(merged, workday,  on='email', how='outer'))\n",
    "\n",
    "deletes = workday.loc[workday.action == 'DELETE'].action.tolist()\n",
    "\n",
    "\n",
    "allmerge.to_csv('allmerge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects.opportynity_id = projects.opportynity_id.astype(str)\n",
    "\n",
    "projects.opportynity_id = [x[:15] for x in projects.opportynity_id]\n",
    "\n",
    "projects.rename(columns = {'opportynity_id': 'opportunity_id'}).head()\n",
    "\n",
    "project_merge = pd.DataFrame(pd.merge(revenue, projects, on='project_id', how='outer'))\n",
    "\n",
    "projects_people_merge = pd.DataFrame(pd.merge(allmerge, project_merge, on='email', how='outer')).fillna('no_data', inplace = True)\n",
    "\n",
    "projects_people_merge.rename(columns = {'client': 'adwire_client', 'group_x': 'adwire_group', 'name_x': 'adwire_name_x',\n",
    "                                       'email': 'adwire_email', 'projects': 'adwire_projects', 'spend': 'adwire_spend',\n",
    "                                       'project_ts': 'adwire_first_posting', 'group_cap': 'adwire_cap', 'owner': 'account_owner',\n",
    "                                       'Worker': 'hr_worker', 'Job Title': 'hr_job_title', 'Business Title': 'hr_business_title',\n",
    "                                       'Hire Date': 'hr_hire_date', 'Phone - Primary Work': 'hr_work_phone',\n",
    "                                       'Mobile Phones': 'hr_mobile_phone', \"Worker's Manager\": 'hr_worker_manager',\n",
    "                                        \"Worker's Manager Business Title\": \"hr_worker_manager_business_title\",\n",
    "                                       \"Worker's Manager's Manager\": \"hr_worker_manager_manager\",\n",
    "                                       \"Worker's Manager's Manager Business Title\": \"hr_worker_manager_manager_business_title\",\n",
    "                                       'Market': 'hr_market', 'Market President': 'hr_market_president', 'Region/Area': 'hr_region/area',\n",
    "                                       'Area/Region/Community President': 'hr_area/region/community_president', 'Division': 'hr_division',\n",
    "                                       'Division President': 'hr_division_president', 'first name_x': 'workday_first_name', \n",
    "                                       'action': 'workday_action', 'client code': 'workday_client_code', 'first name_y': 'workday_first_name2',\n",
    "                                       'last name': 'workday_last_name', 'group_y': 'workday_group_y', 'stage': 'revenue_stage',\n",
    "                                        'market_division': 'revenue_market_division', 'market_area': 'revenue_market_area', 'market': 'revenue_market',\n",
    "                                       'ae_name': 'revenue_ae_name', 'new_business': 'revenue_new_business', 'account': 'revenue_account',\n",
    "                                       'opportunity': 'revenue_opportunity', 'project_id': 'revenue_project_id', 'form_date': 'revenue_form_date',\n",
    "                                       'opportunity_created_date': 'revenue_opportunity_created_date', 'opportunity_closed_date': 'revenue_opportunity_closed_date',\n",
    "                                       'gross_expected_revenue': 'revenue_gross_expected_revenue', 'gross_amount': 'revenue_gross_amount',\n",
    "                                        'form_created_on_closed_opp': 'revenue_form_created_on_closed_opp',\n",
    "                                       'market_type': 'revenue_market_type', 'create_ts': 'adwire_post_date', 'name_y': 'adwire_name_y',\n",
    "                                       'group': 'adwire_group2', 'submissions': 'adwire_submissions', 'opportynity_id': 'adwire_opportunity_id',\n",
    "                                       'credits_used': 'adwire_credits_used', 'industry': 'adwire_industry', 'tone': 'adwire_tone'}, inplace=True)\n",
    "\n",
    "projects_people_merge.to_csv('fullmerge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method IndexOpsMixin.tolist of Index(['client', 'group_x', 'name_x', 'email', 'projects', 'spend',\n",
       "       'project_ts', 'group_cap', 'owner', 'Worker', 'Job Title',\n",
       "       'Business Title', 'Hire Date', 'Phone - Primary Work', 'Mobile Phones',\n",
       "       'Worker's Manager', 'Worker's Manager Business Title',\n",
       "       'Worker's Manager's Manager',\n",
       "       'Worker's Manager's Manager Business Title', 'Market',\n",
       "       'Market President', 'Region/Area', 'Area/Region/Community President',\n",
       "       'Division', 'Division President', 'first name_x', 'action',\n",
       "       'client code', 'first name_y', 'last name', 'group_y', 'stage',\n",
       "       'market_division', 'market_area', 'market', 'ae_name', 'new_business',\n",
       "       'account', 'opportunity', 'project_id', 'form_date',\n",
       "       'opportunity_created_date', 'opportunity_closed_date',\n",
       "       'gross_expected_revenue', 'gross_amount', 'form_created_on_closed_opp',\n",
       "       'market_type', 'create_ts', 'name_y', 'group', 'submissions',\n",
       "       'opportynity_id', 'credits_used', 'industry', 'tone'],\n",
       "      dtype='object')>"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projects_people_merge.columns.tolist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
